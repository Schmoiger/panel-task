{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"faster r-cnn object detection.ipynb","provenance":[],"mount_file_id":"1xjzhIcDds6JgpVH-MrLrao8Ex51bqlji","authorship_tag":"ABX9TyOLsxHKPccx+m//uBTlmt+I"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"npzRblM8IcIb"},"source":["Demonstration code for faster r-cnn object detection. With additional testing functions, to enable testing using PyTest."]},{"cell_type":"code","metadata":{"id":"LK3voS1Q6xCu","executionInfo":{"status":"ok","timestamp":1604500750743,"user_tz":0,"elapsed":903,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["# from https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch/"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yOQr0O0UIwI0"},"source":["Next line is only for this testing environment. wget is not available in Google Golab by default, so need to run shell command to install"]},{"cell_type":"code","metadata":{"id":"GiZMq2ox9C2u","executionInfo":{"status":"ok","timestamp":1604500754064,"user_tz":0,"elapsed":4194,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}},"outputId":"dc4afbfa-4be4-45f3-f8c9-f308bb8b9a29","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install wget"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1_xinwWe4t8p","executionInfo":{"status":"ok","timestamp":1604500755093,"user_tz":0,"elapsed":5191,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}},"outputId":"86eaf17a-f311-4e6d-c0ab-72e9cbfe9d92","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["# import necessary libraries\n","from PIL import Image\n","import torch\n","import torchvision\n","import torchvision.transforms as T\n","import numpy as np\n","'''\n","# following imports are for object_detection_api only\n","import matplotlib.pyplot as plt\n","import cv2\n","'''"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\n# following imports are for object_detection_api only\\nimport matplotlib.pyplot as plt\\nimport cv2\\n'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"aV60pcIL6_UQ","executionInfo":{"status":"ok","timestamp":1604500755096,"user_tz":0,"elapsed":5170,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["# following imports are for the test modules\n","import wget\n","import json\n","import pytest"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"JV9GI3Cq56OI","executionInfo":{"status":"ok","timestamp":1604500757567,"user_tz":0,"elapsed":7622,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}},"outputId":"8628594e-c92b-428a-800d-1e9309962b4d","colab":{"base_uri":"https://localhost:8080/"}},"source":["# get the pretrained model from torchvision.models\n","# Note: pretrained=True will get the pretrained weights for the model.\n","# model.eval() to use the model for inference\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","model.eval()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FasterRCNN(\n","  (transform): GeneralizedRCNNTransform(\n","      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n","  )\n","  (backbone): BackboneWithFPN(\n","    (body): IntermediateLayerGetter(\n","      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (bn1): FrozenBatchNorm2d(64)\n","      (relu): ReLU(inplace=True)\n","      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (layer1): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): FrozenBatchNorm2d(256)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(64)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(64)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(256)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer2): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(512)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(128)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(128)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(512)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer3): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(1024)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(256)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(256)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(1024)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (layer4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): FrozenBatchNorm2d(2048)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): FrozenBatchNorm2d(512)\n","          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): FrozenBatchNorm2d(512)\n","          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): FrozenBatchNorm2d(2048)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (fpn): FeaturePyramidNetwork(\n","      (inner_blocks): ModuleList(\n","        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","      (layer_blocks): ModuleList(\n","        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","      (extra_blocks): LastLevelMaxPool()\n","    )\n","  )\n","  (rpn): RegionProposalNetwork(\n","    (anchor_generator): AnchorGenerator()\n","    (head): RPNHead(\n","      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n","  (roi_heads): RoIHeads(\n","    (box_roi_pool): MultiScaleRoIAlign()\n","    (box_head): TwoMLPHead(\n","      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n","    )\n","    (box_predictor): FastRCNNPredictor(\n","      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n","    )\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"sDFpRIWR58U3","executionInfo":{"status":"ok","timestamp":1604500757568,"user_tz":0,"elapsed":7606,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["# Class labels from official PyTorch documentation for the pretrained model\n","# Note that there are some N/A's\n","# for complete list check https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n","# we will use the same list for this notebook\n","COCO_INSTANCE_CATEGORY_NAMES = [\n","    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n","    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n","    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n","    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n","    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n","    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n","    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n","    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n","    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n","    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n","    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n","    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n","]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hwf4feNL5_mm","executionInfo":{"status":"ok","timestamp":1604500757569,"user_tz":0,"elapsed":7594,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["def get_prediction(img_path, threshold):\n","    \"\"\"\n","    get_prediction\n","      parameters:\n","        - img_path - path of the input image\n","        - threshold - threshold value for prediction score\n","      method:\n","        - Image is obtained from the image path\n","        - the image is converted to image tensor using PyTorch's Transforms\n","        - image is passed through the model to get the predictions\n","        - class, box coordinates are obtained, but only prediction score > threshold\n","          are chosen.\n","\n","    \"\"\"\n","    img = Image.open(img_path)\n","    transform = T.Compose([T.ToTensor()])\n","    img = transform(img)\n","    pred = model([img])\n","    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n","    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n","    pred_score = list(pred[0]['scores'].detach().numpy())\n","    pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1]\n","    pred_boxes = pred_boxes[:pred_t+1]\n","    pred_class = pred_class[:pred_t+1]\n","    return pred_boxes, pred_class"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BR_X-PvJD2s"},"source":["API below gives visual representation. Not used."]},{"cell_type":"code","metadata":{"id":"qhl6eLTt6E3K","executionInfo":{"status":"ok","timestamp":1604500757571,"user_tz":0,"elapsed":7568,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}},"outputId":"7d7b98b1-2daa-4cbf-9e63-87214cfbff40","colab":{"base_uri":"https://localhost:8080/","height":137}},"source":["'''\n","def object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3):\n","    \"\"\"\n","    object_detection_api\n","      parameters:\n","        - img_path - path of the input image\n","        - threshold - threshold value for prediction score\n","        - rect_th - thickness of bounding box\n","        - text_size - size of the class label text\n","        - text_th - thichness of the text\n","      method:\n","        - prediction is obtained from get_prediction method\n","        - for each prediction, bounding box is drawn and text is written\n","          with opencv\n","        - the final image is displayed\n","    \"\"\"\n","    boxes, pred_cls = get_prediction(img_path, threshold)\n","    img = cv2.imread(img_path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    for i in range(len(boxes)):\n","        cv2.rectangle(img, boxes[i][0], boxes[i][1], color=(0, 255, 0), thickness=rect_th)\n","        cv2.putText(img, pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX,\n","                    text_size, (0, 255, 0), thickness=text_th)\n","    plt.figure(figsize=(20, 30))\n","    plt.imshow(img)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.show()\n","'''"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ndef object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=3, text_th=3):\\n    \"\"\"\\n    object_detection_api\\n      parameters:\\n        - img_path - path of the input image\\n        - threshold - threshold value for prediction score\\n        - rect_th - thickness of bounding box\\n        - text_size - size of the class label text\\n        - text_th - thichness of the text\\n      method:\\n        - prediction is obtained from get_prediction method\\n        - for each prediction, bounding box is drawn and text is written\\n          with opencv\\n        - the final image is displayed\\n    \"\"\"\\n    boxes, pred_cls = get_prediction(img_path, threshold)\\n    img = cv2.imread(img_path)\\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n    for i in range(len(boxes)):\\n        cv2.rectangle(img, boxes[i][0], boxes[i][1], color=(0, 255, 0), thickness=rect_th)\\n        cv2.putText(img, pred_cls[i], boxes[i][0], cv2.FONT_HERSHEY_SIMPLEX,\\n                    text_size, (0, 255, 0), thickness=text_th)\\n    plt.figure(figsize=(20, 30))\\n    plt.imshow(img)\\n    plt.xticks([])\\n    plt.yticks([])\\n    plt.show()\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"G1W4QZFLJLI5"},"source":["Next section defines namespace variables to locate the test data. These locations will have to be altered depending upon the environment.\n","\n","The image file has strict syntax rules:\n","- expect all images to be .jpg on a different line\n","- location to be either: 1) relative to TEST_FOLDER;\n","- or 2) full url\n","- TEST_FOLDER = ./tests/ in most environments, except Colab\n","- comments have a hash at beginning of line"]},{"cell_type":"code","metadata":{"id":"DiemEjSz63pu","executionInfo":{"status":"ok","timestamp":1604500757572,"user_tz":0,"elapsed":7552,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["TEST_FOLDER = '/content/drive/My Drive/Colab Notebooks/'\n","IMAGE_FILE = 'images.txt'\n","DETECTION_THRESHOLD = 0.8"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bcHdh3nDJ9pF"},"source":["Helper function to take contents of test data file and parse it into a Python list for processing. Includes downloading in required.\n","\n","Note: the original input text file is unaltered, and the downloaded file is not deleted after use. This means, if this function is run twice, two copies of the file will be downloaded. The OS will handle renaming the downloaded file to avoid overwriting."]},{"cell_type":"code","metadata":{"id":"4V8qYdoF7EJj","executionInfo":{"status":"ok","timestamp":1604500757576,"user_tz":0,"elapsed":7533,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["def parse_images(test_images=TEST_FOLDER+IMAGE_FILE):\n","    # parse images list\n","    try:\n","        with open(test_images) as file:\n","            lines = [line.rstrip() for line in file]\n","        images = [line for line in lines if (line != '' and not(line.startswith('#')))]\n","    except:\n","        error_status = 'invalid image file'\n","        return error_status\n","\n","    # download into tests folder if not already downloaded\n","    for i in range(len(images)):\n","        filename = images[i].rsplit('/', 1)[-1]\n","        if images[i].startswith('http'):\n","            try:\n","                wget.download(images[i], TEST_FOLDER + filename)\n","                images[i] = TEST_FOLDER + filename\n","            except:\n","                pass\n","        else:\n","            images[i] = TEST_FOLDER + filename\n","    \n","    # if not downloadable, remove from list\n","    downloaded_images = [image for image in images if not(image.startswith('http'))]\n","    return downloaded_images"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmhuhiElKMV3"},"source":["Helper function to run image detection list of images, then return results as a JSON file if successful."]},{"cell_type":"code","metadata":{"id":"NXKYTt337HwZ","executionInfo":{"status":"ok","timestamp":1604500757585,"user_tz":0,"elapsed":7524,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["def detect_images(images):\n","    # run object detection on each image\n","    detections = []\n","    for image in images:\n","        _, labels = get_prediction(image, DETECTION_THRESHOLD)\n","        detections.append({\n","            'image_filename': image,\n","            'detections': labels\n","        })\n","\n","    detections_json = json.dumps(detections)\n","    return detections_json"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZZ88DukVYIN-"},"source":["For Colab only, need to install helper library to run PyTest within a notebook"]},{"cell_type":"code","metadata":{"id":"DYPdNNiuYYTZ","executionInfo":{"status":"ok","timestamp":1604500761874,"user_tz":0,"elapsed":11797,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}},"outputId":"9621fb25-3d03-4600-dca3-407ded624f05","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install ipytest"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ipytest in /usr/local/lib/python3.6/dist-packages (0.9.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ipytest) (5.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ipytest) (20.4)\n","Requirement already satisfied: pytest>=5.4 in /usr/local/lib/python3.6/dist-packages (from ipytest) (6.1.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.4.2)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (50.3.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (0.7.5)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (1.0.18)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.8.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (0.8.1)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (4.3.3)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ipytest) (2.6.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->ipytest) (2.4.7)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (20.2.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (0.10.1)\n","Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (2.0.0)\n","Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (0.13.1)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (1.1.1)\n","Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from pytest>=5.4->ipytest) (1.9.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipytest) (0.2.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipytest) (0.6.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ipytest) (0.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=5.4->ipytest) (3.3.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CpI1_znRYRF2","executionInfo":{"status":"ok","timestamp":1604500761875,"user_tz":0,"elapsed":11782,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}}},"source":["import ipytest\n","ipytest.autoconfig()"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RpxfDExuLFhG"},"source":["Test functions to enable PyTest in build pipeline. Fixture (decorator) function inialises as follows:\n","- loads modules\n","- creates images list\n","- runs detection on all images"]},{"cell_type":"markdown","metadata":{"id":"lLiLTqvLA6IH"},"source":["Test 1: \n","- Is the output from detections valid JSON?"]},{"cell_type":"markdown","metadata":{"id":"M_gSsYfIBXbw"},"source":["Test 2:\n","- Did all valid images process? (Did all parsed images yield corresponding result?)"]},{"cell_type":"markdown","metadata":{"id":"Rl1zszYuBhel"},"source":["Test 3:\n","- Did every image yield at least one detection?"]},{"cell_type":"code","metadata":{"id":"55aGcgYDAhrO","executionInfo":{"status":"ok","timestamp":1604508055438,"user_tz":0,"elapsed":55535,"user":{"displayName":"Avi Sinharay","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi41gYnHf6GREpQACKk6TFSkJG5LGvKDFJyGfgASg=s64","userId":"14737652169467905872"}},"outputId":"53bb4083-81c5-4402-c6cc-9610780c4734","colab":{"base_uri":"https://localhost:8080/"}},"source":["%%run_pytest[clean]\n","\n","@pytest.fixture\n","def images_detected(scope=\"session\"):\n","    images = parse_images()\n","    result_json = detect_images(images)\n","    return images, result_json\n","\n","\n","def test_valid_json(images_detected):\n","    images, result_json = images_detected\n","    error = False\n","    try:\n","        r = json.loads(result_json)\n","        error = False\n","    except:\n","        error = True\n","    assert error == False\n","\n","\n","def test_confirm_all_processed(images_detected):\n","    images, result_json = images_detected\n","    error = False\n","    if len(images) == len(json.loads(result_json)):\n","        error = False\n","    else:\n","        error = True\n","    assert error == False\n","\n","\n","def test_at_least_one_result(images_detected):\n","    images, result_json = images_detected\n","    error = False\n","    print(result_json)\n","    for result in json.loads(result_json):\n","        if result['detections'] == []:\n","            error = True\n","        else:\n","            error = error or False\n","    assert error == False\n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["....                                                                     [100%]\n","4 passed in 54.48s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3jg3Yep-LPzm"},"source":["These functions will be separated out in the final package:\n","\n","src:\n","- object_detection.py: training model, category names, get_prediction, object_detection_api;\n","\n","tests:\n","- detect_images.py: parse_images, detect_images;\n","- test_detections.py: test_prerequisites, test_valid_json, test_confirm_all_processed, test_at_least_one_result;\n","- images.txt"]}]}